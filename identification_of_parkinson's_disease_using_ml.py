# -*- coding: utf-8 -*-
"""Identification Of Parkinson's Disease Using - ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_I_YtIcMIGzwebbiRt2tjIx5lsH9Lmhn

**CH.Yuvarajasimha Reddy (AP21110011248)**
"""

!pip install scikit-learn

!pip install scikit-multiflow

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns

from sklearn.preprocessing import StandardScaler

data=pd.read_csv("parkinsons.csv")

data.head()

data.isnull().sum()

target='status'

#distribtion of variables
data['status'].value_counts()

data.info()

columns = data.columns
num_cols = 1
num_rows = (len(columns) + num_cols - 1) // num_cols

# Create separate box plots for each column
plt.figure(figsize=(20, 25))
for i, column in enumerate(columns):
    plt.subplot(num_rows, num_cols, i+1)  # Create subplots
    sns.countplot(x=data[column])
    plt.title(f'count plot of {column}')
    plt.xlabel(column)
plt.tight_layout()
plt.show()

columns = data.columns
num_cols = 2
num_rows = (len(columns) + num_cols - 1) // num_cols

# Create separate box plots for each column
plt.figure(figsize=(20, 15))
for i, column in enumerate(columns):
    plt.subplot(num_rows, num_cols, i+1)  # Create subplots
    sns.boxplot(x=data[column])
    plt.title(f'Box plot of {column}')
    plt.xlabel(column)
plt.tight_layout()
plt.show()

plt.figure(figsize=(20, 15))
sns.pairplot(data)
plt.suptitle('Scatter plot of each pair of columns', y=1.02)
plt.show()

plt.figure(figsize=(20,20))
corr=X.corr()
sns.heatmap(corr, annot=True,cmap='rainbow')

#Data Preprocessing

X =data.drop(columns=['name','status'],axis=1)
y=data['status']

print(X)

data['status'].value_counts()



data['status'].value_counts().plot(kind = 'bar', color = ['blue', 'orange'])

"""** DATA IMBALANCING**

"""

from sklearn.model_selection import train_test_split

from imblearn.over_sampling import SMOTE

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state = 0)

print("Before SMOTE, counts of label '1': {}".format(sum(y == 1)))
print("Before SMOTE, counts of label '0': {} \n".format(sum(y == 0)))

X_sm, y_sm = sm.fit_resample(X, y.ravel())



print("After SMOTE, counts of label '1': {}".format(sum(y_sm == 1)))
print("After SMOTE, counts of label '0': {}".format(sum(y_sm == 0)))

#print(y_res.value_counts())
X_sm.value_counts()

from sklearn.preprocessing import MinMaxScaler

scaler=MinMaxScaler((-1,1))
X=scaler.fit_transform(X_sm)
y=y_sm



X.shape

"""**FEATURE SELECTION**"""

from sklearn import svm
clas = svm.SVC(kernel='linear',gamma='auto',C=2)

from sklearn.feature_selection import RFE
# here we want only one final feature, we do this to produce a ranking
n_features_to_select = 12
rfe1 = RFE(clas, n_features_to_select=n_features_to_select)
rfe1.fit(X_sm, y_sm)
X_rfe2 = rfe1.transform(X_sm)

X_sm.columns[(rfe1.get_support())]

from sklearn.decomposition import PCA

pca=PCA(0.95)
X_pca=pca.fit_transform(X)
print(X.shape)
print(X_pca.shape)

"""**Feature Generation**"""

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

pca_df = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])

print(pca_df)
print(type(pca_df))

"""**Splitting of Data**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_rfe2, y_sm, test_size = 0.2, random_state = 1)

print("Number transactions X_train dataset: ", X_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions X_test dataset: ", X_test.shape)
print("Number transactions y_test dataset: ", y_test.shape)

print("Number transactions y_test dataset: ", y_test)

"""**Model Selection**"""

from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

mod1=KNeighborsClassifier()

model4=mod1.fit(X_train,y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_pred = model4.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

mod=GaussianNB()

model3=mod.fit(X_train,y_train)

y_pred = model3.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

from sklearn.metrics import confusion_matrix
predictions=model4.predict(X_test)

cm = confusion_matrix(y_test,predictions)

#Plot the confusion matrix.
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['0', '1'],
            yticklabels=['0', '1'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

output = pd.DataFrame({target:predictions})
output.to_csv('submission.csv', index=False)

dat1=(0.03327,0.348,0.01893,0.0343,0.04322,0.02919,0.631099,0.605417,-2.93107,0.434326,3.007463,0.430788)
dat2=(0.01484,0.133,0.0095,0.0125,0.02261,0.0043,0.36909,0.776158,-6.08557,0.192375,1.889002,0.174152)

hel=np.asarray(dat1)

datas=hel.reshape(1,-1)

pred2=model3.predict(datas)
pred4=model4.predict(datas)
print("Gaussian Method : ",pred2)
print("KNN Method : ",pred4)